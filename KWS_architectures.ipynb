{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f58f176",
   "metadata": {},
   "source": [
    "# Keyword Spotting with different architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341fb838",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 15:19:29.421428: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 15:19:29.583043: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-09 15:19:29.588123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 15:19:29.588141: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 15:19:30.285834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 15:19:30.285919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 15:19:30.285929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1234)\n",
    "\n",
    "from os.path import join as pjoin\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from load_utils import load_dataset, load_dataset_keywords\n",
    "from CNNarchitectures import KWS_CNN_model\n",
    "from CRNN_architecture import KWS_CRNN_model\n",
    "from Autoencoder_architecture import build_autoencoder\n",
    "CHECKPOINTS_PATH = 'models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1eed0a",
   "metadata": {},
   "source": [
    "## Training increasing keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602af699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with different keywords\n",
    "data_dir = 'speechdataset/processed_data'\n",
    "\n",
    "categories = ['marvin', 'no', 'yes', 'bed', 'down', 'forward', 'happy', 'house', 'tree', 'visual', 'bird',\n",
    "              'eight', 'four', 'learn','right', 'stop', 'two', 'wow', 'cat', 'five', 'nine', 'one', 'six',\n",
    "              'go', 'left', 'off', 'seven', 'up', 'backward', 'dog', 'follow', 'on', 'sheila', 'three', 'zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de75b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with  4 keywords: ['marvin', 'no', 'yes', 'bed']\n",
      "Loading data...\n",
      "Data loaded. Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 19:39:53.291788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-20 19:39:53.293850: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-20 19:39:53.293914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-20 19:39:53.293952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-20 19:39:53.331970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-12-20 19:39:53.332035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-12-20 19:39:53.332052: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-12-20 19:39:53.332694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1076s 133ms/step - loss: 0.2761 - accuracy: 0.9217 - val_loss: 0.1730 - val_accuracy: 0.9484\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1071s 132ms/step - loss: 0.1484 - accuracy: 0.9536 - val_loss: 0.1304 - val_accuracy: 0.9589\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1041s 129ms/step - loss: 0.1164 - accuracy: 0.9630 - val_loss: 0.1151 - val_accuracy: 0.9680\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 994s 123ms/step - loss: 0.0989 - accuracy: 0.9693 - val_loss: 0.1207 - val_accuracy: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNbestmodel_25ms_20ms_26_4keywords/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNbestmodel_25ms_20ms_26_4keywords/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 71s - loss: 0.1223 - accuracy: 0.9681 - 71s/epoch - 143ms/step\n",
      "Test accuracy: 96.81%\n",
      "Training with  5 keywords: ['marvin', 'no', 'yes', 'bed', 'down']\n",
      "Loading data...\n",
      "Data loaded. Training...\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1054s 130ms/step - loss: 0.3760 - accuracy: 0.8923 - val_loss: 0.3433 - val_accuracy: 0.8935\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1067s 132ms/step - loss: 0.2017 - accuracy: 0.9372 - val_loss: 0.2068 - val_accuracy: 0.9416\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1076s 133ms/step - loss: 0.1559 - accuracy: 0.9508 - val_loss: 0.1719 - val_accuracy: 0.9484\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 1081s 134ms/step - loss: 0.1325 - accuracy: 0.9588 - val_loss: 0.1438 - val_accuracy: 0.9561\n",
      "Epoch 5/5\n",
      "8096/8096 [==============================] - 1079s 133ms/step - loss: 0.1135 - accuracy: 0.9646 - val_loss: 0.1478 - val_accuracy: 0.9578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNbestmodel_25ms_20ms_26_5keywords/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNbestmodel_25ms_20ms_26_5keywords/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 77s - loss: 0.1569 - accuracy: 0.9548 - 77s/epoch - 154ms/step\n",
      "Test accuracy: 95.48%\n",
      "Training with  6 keywords: ['marvin', 'no', 'yes', 'bed', 'down', 'forward']\n",
      "Loading data...\n",
      "Data loaded. Training...\n",
      "Epoch 1/5\n",
      "3970/8096 [=============>................] - ETA: 8:49 - loss: 0.5615 - accuracy: 0.8536"
     ]
    }
   ],
   "source": [
    "# Early stopping criteria\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=1)\n",
    "\n",
    "\n",
    "for n_keywords in np.arange(4, 11, 1):\n",
    "    keywords = categories[:int(n_keywords)]\n",
    "    n_labels = n_keywords + 1 # number of keywords + not a keyword\n",
    "\n",
    "    print(f'Training with ', n_keywords, 'keywords:', keywords)\n",
    "    \n",
    "    print('Loading data...')\n",
    "    # Load data\n",
    "    X_train, Y_train, X_test, Y_test = load_dataset_keywords(data_dir, keywords, categories, frames=50,\n",
    "                                                             winlen=0.025, winstep=0.02, nfilt=26)\n",
    "    print('Data loaded. Training...')\n",
    "    model = KWS_CNN_model((50,39,1), n_labels, dropout=0.2, norm='False')\n",
    "    model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(np.transpose(X_train, [2,0,1]), tf.one_hot(Y_train, n_labels, 1, 0), epochs=5, batch_size=10,\n",
    "                        validation_split=0.1, callbacks=[early_stop_callback])\n",
    "\n",
    "    model.save(pjoin(CHECKPOINTS_PATH, f'CNNbestmodel_25ms_20ms_26_{n_keywords}keywords'))\n",
    "\n",
    "    loss, acc = model.evaluate(np.transpose(X_test, [2,0,1]), tf.one_hot(Y_test, n_labels, 1, 0), verbose=2)\n",
    "    print(\"Test accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6406d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best model with  3 keywords: ['marvin', 'no', 'yes']\n",
      "497/497 - 77s - loss: 15.5260 - accuracy: 0.8963 - 77s/epoch - 154ms/step\n",
      "Training best model with  4 keywords: ['marvin', 'no', 'yes', 'bed']\n",
      "Loading data...\n",
      "497/497 - 77s - loss: 0.1064 - accuracy: 0.9747 - 77s/epoch - 155ms/step\n",
      "Test accuracy: 97.47401476% \n",
      "\n",
      "Training best model with  5 keywords: ['marvin', 'no', 'yes', 'bed', 'down']\n",
      "Loading data...\n",
      "497/497 - 75s - loss: 0.1261 - accuracy: 0.9621 - 75s/epoch - 151ms/step\n",
      "Test accuracy: 96.21417522% \n",
      "\n",
      "Training best model with  6 keywords: ['marvin', 'no', 'yes', 'bed', 'down', 'forward']\n",
      "Loading data...\n",
      "497/497 - 76s - loss: 0.1436 - accuracy: 0.9591 - 76s/epoch - 152ms/step\n",
      "Test accuracy: 95.90551257% \n",
      "\n",
      "Training best model with  7 keywords: ['marvin', 'no', 'yes', 'bed', 'down', 'forward', 'happy']\n",
      "Loading data...\n",
      "497/497 - 75s - loss: 0.1456 - accuracy: 0.9570 - 75s/epoch - 151ms/step\n",
      "Test accuracy: 95.69763541% \n",
      "\n",
      "Training best model with  8 keywords: ['marvin', 'no', 'yes', 'bed', 'down', 'forward', 'happy', 'house']\n",
      "Loading data...\n",
      "497/497 - 76s - loss: 0.1518 - accuracy: 0.9541 - 76s/epoch - 153ms/step\n",
      "Test accuracy: 95.41417360% \n",
      "\n",
      "Training best model with  9 keywords: ['marvin', 'no', 'yes', 'bed', 'down', 'forward', 'happy', 'house', 'tree']\n",
      "Loading data...\n",
      "497/497 - 76s - loss: 0.2319 - accuracy: 0.9335 - 76s/epoch - 153ms/step\n",
      "Test accuracy: 93.34803224% \n",
      "\n",
      "Training best model with  10 keywords: ['marvin', 'no', 'yes', 'bed', 'down', 'forward', 'happy', 'house', 'tree', 'visual']\n",
      "Loading data...\n",
      "497/497 - 76s - loss: 0.2284 - accuracy: 0.9307 - 76s/epoch - 153ms/step\n",
      "Test accuracy: 93.07086468% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "print(f'Training best model with ', 3, 'keywords:', ['marvin', 'no', 'yes'])\n",
    "# Load data\n",
    "X_train, Y_train, X_test, Y_test = load_dataset_keywords(data_dir, ['marvin', 'no', 'yes'], categories, frames=50,\n",
    "                                                         winlen=0.025, winstep=0.02, nfilt=26)\n",
    "new_model = tf.keras.models.load_model(pjoin(CHECKPOINTS_PATH,\n",
    "                                            f'CNNmodel_25ms_20ms_26_dropout20'))\n",
    "loss, acc = new_model.evaluate(np.transpose(X_test, [2,0,1]), tf.one_hot(Y_test, 4, 1, 0), verbose=2)\n",
    "print(\"Test accuracy: {:5.8f}%\".format(100 * acc), \"\\n\")\n",
    "\n",
    "for n_keywords in np.arange(4, 11, 1):\n",
    "    keywords = categories[:int(n_keywords)]\n",
    "    n_labels = n_keywords + 1 # number of keywords + not a keyword\n",
    "    print(f'Training best model with ', n_keywords, 'keywords:', keywords)\n",
    "    print('Loading data...')\n",
    "    # Load data\n",
    "    X_train, Y_train, X_test, Y_test = load_dataset_keywords(data_dir, keywords, categories, frames=50,\n",
    "                                                             winlen=0.025, winstep=0.02, nfilt=26)\n",
    "    new_model = tf.keras.models.load_model(pjoin(CHECKPOINTS_PATH,\n",
    "                                                 f'CNNbestmodel_25ms_20ms_26_{n_keywords}keywords'))\n",
    "    loss, acc = new_model.evaluate(np.transpose(X_test, [2,0,1]), tf.one_hot(Y_test, n_labels, 1, 0), verbose=2)\n",
    "    print(\"Test accuracy: {:5.8f}%\".format(100 * acc), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131055a0",
   "metadata": {},
   "source": [
    "## Training with increasing dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b02fa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'speechdataset/processed_data'\n",
    "\n",
    "keywords = ['marvin', 'no', 'yes']\n",
    "\n",
    "categories = ['bed', 'down', 'forward', 'house', 'nine', 'one', 'six', 'tree', 'visual', 'bird', 'eight', \n",
    "              'four', 'learn', 'no','right', 'stop', 'two', 'wow', 'cat', 'five', 'go', 'left', 'off', \n",
    "              'seven', 'up', 'yes', 'backward', 'dog', 'follow', 'happy', 'marvin', 'on', 'sheila', 'three', 'zero']\n",
    "\n",
    "n_labels = len(keywords) + 1 # number of keywords + not a keyword\n",
    "\n",
    "# Load data\n",
    "X_train, Y_train, X_test, Y_test = load_dataset_keywords(data_dir, keywords, categories, frames=50,\n",
    "                                                         winlen=0.025, winstep=0.02, nfilt=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4778417b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with  0.1 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 980s 121ms/step - loss: 0.2266 - accuracy: 0.9384 - val_loss: 0.1349 - val_accuracy: 0.9576\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 996s 123ms/step - loss: 0.1100 - accuracy: 0.9660 - val_loss: 0.1092 - val_accuracy: 0.9663\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1030s 127ms/step - loss: 0.0847 - accuracy: 0.9744 - val_loss: 0.1170 - val_accuracy: 0.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout10/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout10/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 78s - loss: 0.1177 - accuracy: 0.9640 - 78s/epoch - 156ms/step\n",
      "Test accuracy: 96.40%\n",
      "Training with  0.15 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1095s 135ms/step - loss: 0.2359 - accuracy: 0.9363 - val_loss: 0.1321 - val_accuracy: 0.9572\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1089s 134ms/step - loss: 0.1157 - accuracy: 0.9636 - val_loss: 0.1088 - val_accuracy: 0.9660\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1119s 138ms/step - loss: 0.0885 - accuracy: 0.9727 - val_loss: 0.0933 - val_accuracy: 0.9741\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 1084s 134ms/step - loss: 0.0750 - accuracy: 0.9772 - val_loss: 0.0819 - val_accuracy: 0.9742\n",
      "Epoch 5/5\n",
      "8096/8096 [==============================] - 1083s 134ms/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.0867 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout15/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout15/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 77s - loss: 0.0770 - accuracy: 0.9744 - 77s/epoch - 156ms/step\n",
      "Test accuracy: 97.44%\n",
      "Training with  0.25 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1094s 135ms/step - loss: 0.2300 - accuracy: 0.9382 - val_loss: 0.1167 - val_accuracy: 0.9633\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1083s 134ms/step - loss: 0.1159 - accuracy: 0.9637 - val_loss: 0.1295 - val_accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout25/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout25/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 78s - loss: 0.1315 - accuracy: 0.9712 - 78s/epoch - 156ms/step\n",
      "Test accuracy: 97.12%\n",
      "Training with  0.3 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1098s 136ms/step - loss: 0.2366 - accuracy: 0.9361 - val_loss: 0.1898 - val_accuracy: 0.9499\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1024s 126ms/step - loss: 0.1160 - accuracy: 0.9632 - val_loss: 0.1260 - val_accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1009s 125ms/step - loss: 0.0932 - accuracy: 0.9707 - val_loss: 0.1172 - val_accuracy: 0.9712\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 1041s 129ms/step - loss: 0.0776 - accuracy: 0.9757 - val_loss: 0.0902 - val_accuracy: 0.9749\n",
      "Epoch 5/5\n",
      "8096/8096 [==============================] - 1032s 127ms/step - loss: 0.0681 - accuracy: 0.9794 - val_loss: 0.1082 - val_accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout30/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout30/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 71s - loss: 0.1087 - accuracy: 0.9711 - 71s/epoch - 143ms/step\n",
      "Test accuracy: 97.11%\n",
      "Training with  0.35 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 997s 123ms/step - loss: 0.2385 - accuracy: 0.9341 - val_loss: 0.1987 - val_accuracy: 0.9548\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1004s 124ms/step - loss: 0.1215 - accuracy: 0.9616 - val_loss: 0.1210 - val_accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 992s 122ms/step - loss: 0.0953 - accuracy: 0.9695 - val_loss: 0.1016 - val_accuracy: 0.9742\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 983s 121ms/step - loss: 0.0794 - accuracy: 0.9758 - val_loss: 0.1118 - val_accuracy: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout35/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout35/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 71s - loss: 0.1128 - accuracy: 0.9724 - 71s/epoch - 142ms/step\n",
      "Test accuracy: 97.24%\n",
      "Training with  0.4 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 989s 122ms/step - loss: 0.2355 - accuracy: 0.9356 - val_loss: 0.1397 - val_accuracy: 0.9516\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 977s 121ms/step - loss: 0.1200 - accuracy: 0.9620 - val_loss: 0.1320 - val_accuracy: 0.9640\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1060s 131ms/step - loss: 0.0978 - accuracy: 0.9697 - val_loss: 0.1048 - val_accuracy: 0.9698\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 1078s 133ms/step - loss: 0.0823 - accuracy: 0.9745 - val_loss: 0.1341 - val_accuracy: 0.9712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout40/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout40/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 77s - loss: 0.1322 - accuracy: 0.9736 - 77s/epoch - 155ms/step\n",
      "Test accuracy: 97.36%\n",
      "Training with  0.45 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1089s 134ms/step - loss: 0.2393 - accuracy: 0.9339 - val_loss: 0.1944 - val_accuracy: 0.9589\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1083s 134ms/step - loss: 0.1254 - accuracy: 0.9611 - val_loss: 0.1418 - val_accuracy: 0.9670\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1082s 134ms/step - loss: 0.1023 - accuracy: 0.9684 - val_loss: 0.1519 - val_accuracy: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout45/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout45/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 78s - loss: 0.1484 - accuracy: 0.9697 - 78s/epoch - 156ms/step\n",
      "Test accuracy: 96.97%\n",
      "Training with  0.5 dropout\n",
      "Epoch 1/5\n",
      "8096/8096 [==============================] - 1089s 134ms/step - loss: 0.2496 - accuracy: 0.9321 - val_loss: 0.1751 - val_accuracy: 0.9515\n",
      "Epoch 2/5\n",
      "8096/8096 [==============================] - 1077s 133ms/step - loss: 0.1314 - accuracy: 0.9589 - val_loss: 0.1636 - val_accuracy: 0.9542\n",
      "Epoch 3/5\n",
      "8096/8096 [==============================] - 1085s 134ms/step - loss: 0.1029 - accuracy: 0.9678 - val_loss: 0.1178 - val_accuracy: 0.9648\n",
      "Epoch 4/5\n",
      "8096/8096 [==============================] - 1058s 131ms/step - loss: 0.0897 - accuracy: 0.9723 - val_loss: 0.1117 - val_accuracy: 0.9703\n",
      "Epoch 5/5\n",
      "8096/8096 [==============================] - 1005s 124ms/step - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.1136 - val_accuracy: 0.9711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout50/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNNmodel_25ms_20ms_26_dropout50/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 75s - loss: 0.1100 - accuracy: 0.9740 - 75s/epoch - 151ms/step\n",
      "Test accuracy: 97.40%\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "dropouts = [0.1, 0.15, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "norm = 'False'\n",
    "\n",
    "# Early stopping criteria\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=1)\n",
    "\n",
    "\n",
    "for dropout in dropouts:\n",
    "    print(f'Training with ', dropout, 'dropout')\n",
    "\n",
    "    model = KWS_CNN_model((50,39,1), dropout=dropout, norm=norm)\n",
    "    model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(np.transpose(X_train, [2,0,1]), tf.one_hot(Y_train, n_labels, 1, 0), epochs=5, batch_size=10,\n",
    "                        validation_split=0.1, callbacks=[early_stop_callback])\n",
    "\n",
    "    model.save(pjoin(CHECKPOINTS_PATH, f'CNNmodel_25ms_20ms_26_dropout{int(dropout*100)}'))\n",
    "\n",
    "    loss, acc = model.evaluate(np.transpose(X_test, [2,0,1]), tf.one_hot(Y_test, n_labels, 1, 0), verbose=2)\n",
    "    print(\"Test accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f878ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 0.1 dropout\n",
      "497/497 - 76s - loss: 0.1177 - accuracy: 0.9640 - 76s/epoch - 153ms/step\n",
      "Test accuracy: 96.39685154% \n",
      "\n",
      "Training with 0.15 dropout\n",
      "497/497 - 76s - loss: 0.0770 - accuracy: 0.9744 - 76s/epoch - 154ms/step\n",
      "Test accuracy: 97.43621945% \n",
      "\n",
      "Training with 0.2 dropout\n",
      "497/497 - 76s - loss: 0.0925 - accuracy: 0.9772 - 76s/epoch - 153ms/step\n",
      "Test accuracy: 97.71968722% \n",
      "\n",
      "Training with 0.25 dropout\n",
      "497/497 - 77s - loss: 0.1315 - accuracy: 0.9712 - 77s/epoch - 154ms/step\n",
      "Test accuracy: 97.12126255% \n",
      "\n",
      "Training with 0.3 dropout\n",
      "497/497 - 78s - loss: 0.1087 - accuracy: 0.9711 - 78s/epoch - 157ms/step\n",
      "Test accuracy: 97.10866213% \n",
      "\n",
      "Training with 0.35 dropout\n",
      "497/497 - 79s - loss: 0.1128 - accuracy: 0.9724 - 79s/epoch - 158ms/step\n",
      "Test accuracy: 97.24094272% \n",
      "\n",
      "Training with 0.4 dropout\n",
      "497/497 - 78s - loss: 0.1322 - accuracy: 0.9736 - 78s/epoch - 157ms/step\n",
      "Test accuracy: 97.36062884% \n",
      "\n",
      "Training with 0.45 dropout\n",
      "497/497 - 77s - loss: 0.1484 - accuracy: 0.9697 - 77s/epoch - 155ms/step\n",
      "Test accuracy: 96.97008133% \n",
      "\n",
      "Training with 0.5 dropout\n",
      "497/497 - 77s - loss: 0.1100 - accuracy: 0.9740 - 77s/epoch - 155ms/step\n",
      "Test accuracy: 97.40472436% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropouts = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "for dropout in dropouts:\n",
    "    print(f'Training with', dropout, 'dropout')\n",
    "    new_model = tf.keras.models.load_model(pjoin(CHECKPOINTS_PATH,\n",
    "                                                 f'CNNmodel_25ms_20ms_26_dropout{int(dropout*100)}'))\n",
    "    loss, acc = new_model.evaluate(np.transpose(X_test, [2,0,1]), tf.one_hot(Y_test, n_labels, 1, 0), verbose=2)\n",
    "    print(\"Test accuracy: {:5.8f}%\".format(100 * acc), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9bad83",
   "metadata": {},
   "source": [
    "## Training with CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c464bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'speechdataset/processed_data'\n",
    "\n",
    "keywords = ['marvin', 'no', 'yes']\n",
    "\n",
    "categories = ['bed', 'down', 'forward', 'house', 'nine', 'one', 'six', 'tree', 'visual', 'bird', 'eight', \n",
    "              'four', 'learn', 'no','right', 'stop', 'two', 'wow', 'cat', 'five', 'go', 'left', 'off', \n",
    "              'seven', 'up', 'yes', 'backward', 'dog', 'follow', 'happy', 'marvin', 'on', 'sheila', 'three', 'zero']\n",
    "\n",
    "n_labels = len(keywords) + 1 # number of keywords + not a keyword\n",
    "\n",
    "# Load data\n",
    "X_train, Y_train, X_test, Y_test = load_dataset_keywords(data_dir, keywords, categories, frames=50,\n",
    "                                                         winlen=0.025, winstep=0.02, nfilt=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04282ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 09:22:04.320163: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-08 09:22:04.321802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-08 09:22:04.321866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 09:22:04.321909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 09:22:04.357404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-08 09:22:04.357472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-08 09:22:04.357493: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-08 09:22:04.358076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1549/8096 [====>.........................] - ETA: 12:15 - loss: 0.3202 - accuracy: 0.9208"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m KWS_CRNN_model((\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m39\u001b[39m,\u001b[38;5;241m1\u001b[39m), n_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(), metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_hot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# save\u001b[39;00m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39msave(pjoin(CHECKPOINTS_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCRNNmodel_25ms_20ms_26\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Early stopping criteria\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=1)\n",
    "\n",
    "# train\n",
    "model = KWS_CRNN_model((50,39,1), n_outputs=4)\n",
    "model.compile(optimizer=\"adam\", loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(np.transpose(X_train, [2,0,1]), tf.one_hot(Y_train, n_labels, 1, 0), epochs=5, batch_size=10,\n",
    "          validation_split=0.1, callbacks=[early_stop_callback])\n",
    "\n",
    "# save\n",
    "model.save(pjoin(CHECKPOINTS_PATH, f'CRNNmodel_25ms_20ms_26'))\n",
    "\n",
    "# test\n",
    "loss, acc = model.evaluate(np.transpose(X_test, [2,0,1]), tf.one_hot(Y_test, n_labels, 1, 0), verbose=2)\n",
    "print(\"Test accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5806f8",
   "metadata": {},
   "source": [
    "## Training with Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113fafa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'speechdataset/processed_data'\n",
    "\n",
    "keywords = ['marvin', 'no', 'yes']\n",
    "\n",
    "categories = ['bed', 'down', 'forward', 'house', 'nine', 'one', 'six', 'tree', 'visual', 'bird', 'eight', \n",
    "              'four', 'learn', 'no','right', 'stop', 'two', 'wow', 'cat', 'five', 'go', 'left', 'off', \n",
    "              'seven', 'up', 'yes', 'backward', 'dog', 'follow', 'happy', 'marvin', 'on', 'sheila', 'three', 'zero']\n",
    "\n",
    "n_labels = len(keywords) + 1 # number of keywords + not a keyword\n",
    "\n",
    "# Load data\n",
    "X_train, Y_train, X_test, Y_test = load_dataset_keywords(data_dir, keywords, categories, frames=50,\n",
    "                                                         winlen=0.025, winstep=0.02, nfilt=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f3bc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2699/2699 [==============================] - 185s 67ms/step - loss: 30.0405 - val_loss: 26.9403\n",
      "Epoch 2/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 25.3774 - val_loss: 24.3301\n",
      "Epoch 3/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 23.7757 - val_loss: 23.1439\n",
      "Epoch 4/100\n",
      "2699/2699 [==============================] - 179s 66ms/step - loss: 22.6870 - val_loss: 22.3281\n",
      "Epoch 5/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 21.9768 - val_loss: 21.9845\n",
      "Epoch 6/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 21.6387 - val_loss: 21.6506\n",
      "Epoch 7/100\n",
      "2699/2699 [==============================] - 180s 67ms/step - loss: 20.9467 - val_loss: 20.8391\n",
      "Epoch 8/100\n",
      "2699/2699 [==============================] - 180s 67ms/step - loss: 20.3926 - val_loss: 20.5525\n",
      "Epoch 9/100\n",
      "2699/2699 [==============================] - 177s 65ms/step - loss: 20.0422 - val_loss: 20.2344\n",
      "Epoch 10/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 19.6378 - val_loss: 19.9602\n",
      "Epoch 11/100\n",
      "2699/2699 [==============================] - 182s 68ms/step - loss: 19.2999 - val_loss: 19.6547\n",
      "Epoch 12/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 18.9921 - val_loss: 19.5464\n",
      "Epoch 13/100\n",
      "2699/2699 [==============================] - 179s 66ms/step - loss: 18.8133 - val_loss: 19.4282\n",
      "Epoch 14/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 18.6791 - val_loss: 19.3902\n",
      "Epoch 15/100\n",
      "2699/2699 [==============================] - 179s 66ms/step - loss: 18.5306 - val_loss: 19.1561\n",
      "Epoch 16/100\n",
      "2699/2699 [==============================] - 178s 66ms/step - loss: 18.2461 - val_loss: 18.8975\n",
      "Epoch 17/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 18.0745 - val_loss: 18.8563\n",
      "Epoch 18/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 17.9532 - val_loss: 18.7995\n",
      "Epoch 19/100\n",
      "2699/2699 [==============================] - 177s 65ms/step - loss: 17.7829 - val_loss: 18.6817\n",
      "Epoch 20/100\n",
      "2699/2699 [==============================] - 178s 66ms/step - loss: 17.5966 - val_loss: 18.4862\n",
      "Epoch 21/100\n",
      "2699/2699 [==============================] - 178s 66ms/step - loss: 17.4377 - val_loss: 18.3464\n",
      "Epoch 22/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 17.2678 - val_loss: 18.2498\n",
      "Epoch 23/100\n",
      "2699/2699 [==============================] - 177s 65ms/step - loss: 17.1296 - val_loss: 18.0941\n",
      "Epoch 24/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 17.0097 - val_loss: 18.0440\n",
      "Epoch 25/100\n",
      "2699/2699 [==============================] - 179s 66ms/step - loss: 16.8613 - val_loss: 17.9401\n",
      "Epoch 26/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 16.7123 - val_loss: 17.8137\n",
      "Epoch 27/100\n",
      "2699/2699 [==============================] - 179s 66ms/step - loss: 16.6099 - val_loss: 17.8316\n",
      "Epoch 28/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 16.5284 - val_loss: 17.7530\n",
      "Epoch 29/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 16.4562 - val_loss: 17.8066\n",
      "Epoch 30/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 16.3892 - val_loss: 17.7512\n",
      "Epoch 31/100\n",
      "2699/2699 [==============================] - 178s 66ms/step - loss: 16.3029 - val_loss: 17.6346\n",
      "Epoch 32/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 16.1920 - val_loss: 17.5609\n",
      "Epoch 33/100\n",
      "2699/2699 [==============================] - 177s 65ms/step - loss: 16.1045 - val_loss: 17.5308\n",
      "Epoch 34/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 16.0335 - val_loss: 17.4617\n",
      "Epoch 35/100\n",
      "2699/2699 [==============================] - 180s 67ms/step - loss: 15.9761 - val_loss: 17.5175\n",
      "Epoch 36/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 15.9154 - val_loss: 17.4159\n",
      "Epoch 37/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 15.8514 - val_loss: 17.4010\n",
      "Epoch 38/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 15.7724 - val_loss: 17.2723\n",
      "Epoch 39/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 15.7013 - val_loss: 17.2562\n",
      "Epoch 40/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 15.6408 - val_loss: 17.2666\n",
      "Epoch 41/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 15.5842 - val_loss: 17.2058\n",
      "Epoch 42/100\n",
      "2699/2699 [==============================] - 177s 65ms/step - loss: 15.5350 - val_loss: 17.2233\n",
      "Epoch 43/100\n",
      "2699/2699 [==============================] - 176s 65ms/step - loss: 15.4781 - val_loss: 17.1147\n",
      "Epoch 44/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 15.4099 - val_loss: 17.0736\n",
      "Epoch 45/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 15.3351 - val_loss: 17.0316\n",
      "Epoch 46/100\n",
      "2699/2699 [==============================] - 177s 66ms/step - loss: 15.2737 - val_loss: 17.0064\n",
      "Epoch 47/100\n",
      "2699/2699 [==============================] - 178s 66ms/step - loss: 15.2250 - val_loss: 16.9272\n",
      "Epoch 48/100\n",
      "2699/2699 [==============================] - 178s 66ms/step - loss: 15.1833 - val_loss: 16.9993\n",
      "Epoch 49/100\n",
      "2699/2699 [==============================] - 177s 65ms/step - loss: 15.1394 - val_loss: 17.0139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/AutoencoderModel2img_dcrnn_25ms_20ms_26/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/AutoencoderModel2img_dcrnn_25ms_20ms_26/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 - 14s - loss: 17.0525 - 14s/epoch - 28ms/step\n",
      "Test loss: 17.05\n"
     ]
    }
   ],
   "source": [
    "# Early stopping criteria\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=2)\n",
    "\n",
    "# train\n",
    "model_type = 'img_dcrnn'\n",
    "encoder, decoder, autoencoder = build_autoencoder((50,39,1), 24, model_type=model_type)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=None)\n",
    "\n",
    "autoencoder.fit(np.transpose(X_train, [2,0,1]), np.transpose(X_train, [2,0,1]), epochs=100, batch_size=30,\n",
    "                validation_split=0.1, callbacks=[early_stop_callback])\n",
    "\n",
    "# save\n",
    "encoder.save_weights(CHECKPOINTS_PATH + 'EncoderWeights{}_25ms_20ms_26'.format(model_type))\n",
    "decoder.save_weights(CHECKPOINTS_PATH + 'DecoderWeights{}_25ms_20ms_26'.format(model_type))\n",
    "autoencoder.save(pjoin(CHECKPOINTS_PATH, f'AutoencoderModel2{model_type}_25ms_20ms_26'))\n",
    "\n",
    "# test\n",
    "loss = autoencoder.evaluate(np.transpose(X_test, [2,0,1]), np.transpose(X_test, [2,0,1]), verbose=2)\n",
    "print(\"Test loss: {:5.2f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb361972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2812/2812 [==============================] - 37s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n",
      "2023-01-09 18:50:08.138271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 18:50:08.297307: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-09 18:50:08.303183: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:08.338244: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 18:50:09.065914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.066002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.066011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-09 18:50:09.148545: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 18:50:09.168921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 18:50:09.173103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 18:50:09.290004: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-09 18:50:09.294119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.294142: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 18:50:09.304977: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-09 18:50:09.306064: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-09 18:50:09.309284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.309309: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 18:50:09.309906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.309926: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-09 18:50:09.987546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.987624: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:09.987632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-09 18:50:10.005132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.005222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.005234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-09 18:50:10.035632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.035777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.035794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-09 18:50:10.079569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 18:50:10.081262: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.081336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.081389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.121336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.121418: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:10.121445: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-09 18:50:10.121859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-09 18:50:11.037671: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 18:50:11.045114: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 18:50:11.047770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.047911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.047973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.048768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.048882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.048950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.085955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.086044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.086060: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-09 18:50:11.086445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 18:50:11.086607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.086693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.086711: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-09 18:50:11.087037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-09 18:50:11.101362: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-09 18:50:11.103026: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.103110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.103172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.139969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.140081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-01-09 18:50:11.140099: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-01-09 18:50:11.140501: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[Parallel(n_jobs=15)]: Done   2 out of   4 | elapsed:   26.1s remaining:   26.1s\n",
      "[Parallel(n_jobs=15)]: Done   4 out of   4 | elapsed:  2.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=15)]: Done   4 out of   4 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497/497 [==============================] - 7s 13ms/step\n",
      "CRNN autoencoder + SVM accuracy:\t 93.06 %\n"
     ]
    }
   ],
   "source": [
    "# Classify with SVM on the code\n",
    "# SVM for multiclass One-vs-Rest\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "svm = SVC()\n",
    "crnn_ae_classifier = OneVsRestClassifier(svm, verbose=5, n_jobs=15)\n",
    "Z_train = encoder.predict(np.transpose(X_train, [2,0,1]))\n",
    "crnn_ae_classifier.fit(tf.keras.layers.Flatten()(Z_train), Y_train)\n",
    "Z_test = encoder.predict(np.transpose(X_test, [2,0,1]))\n",
    "prediction = crnn_ae_classifier.predict(tf.keras.layers.Flatten()(Z_test))\n",
    "# Measure performance\n",
    "count = 0\n",
    "for idx, label in enumerate(prediction):\n",
    "    if label == Y_test[idx]:\n",
    "        count += 1\n",
    "acc = 100 * count / len(Y_test)\n",
    "print(f'CRNN autoencoder + SVM accuracy:\\t {acc:2.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162489d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
